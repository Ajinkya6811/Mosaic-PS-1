# -*- coding: utf-8 -*-
"""Copy of Captcha_Recognition_Sigmoids_final_submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EeNUOuKs78EXObxuZRHchk6XKVEyFHJU
"""


import pandas as pd 
import cv2 
import imutils
import tensorflow as tf
from tensorflow import keras
import numpy as np
import glob
from PIL import Image
import os

# from google.colab.patches import cv2_imshow 
# path=str(os.getcwdb())
# print("jk")
# print(path)
# print("jk")
# img= cv2.imread(r"C:\Users\Ashish\Desktop\submission\test.jpeg",1)   # complete path of the captcha image to be recognised
img= cv2.imread("5.png",1)

ht,wt,ch=img.shape
defx=300                                                                      #resize image to width 300 and height in proportion
defh=defx*(ht/wt)

imgr = cv2.resize(img, (defx,(int)(defh)),interpolation = cv2.INTER_NEAREST)
# cv2_imshow(imgr)
cv2.imshow("image",imgr)
print(imgr.shape)

#Different operation on original image for correct contour detection
img1 = cv2.cvtColor(imgr, cv2.COLOR_BGR2GRAY)
# cv2_imshow(img1)
cv2.imshow("image",img1)

# blur = cv2.GaussianBlur(img1,(5,5),0)
blur = cv2.GaussianBlur(img1,(5,5),0)           #removes disturbance, noise in image
edged = cv2.Canny(blur, 50, 150)                #canny edge detection

# kernal = np.ones((5,5),dtype=np.uint8)
kernal = np.ones((3,3),dtype=np.uint8)
dilation = cv2.dilate(edged,kernal,iterations=1)  

# cv2_imshow(dilation)
cv2.imshow("image",dilation)



#function to sort contours from left to right

def sort_contours(cnts, method="left-to-right"):
	reverse = False
	i = 0
	if method == "right-to-left" or method == "bottom-to-top":
		reverse = True

	if method == "top-to-bottom" or method == "bottom-to-top":
		i = 1

	boundingBoxes = [cv2.boundingRect(c) for c in cnts]
	(cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),
		key=lambda b:b[1][i], reverse=reverse))
 
	# return the list of sorted contours and bounding boxes
	return (cnts, boundingBoxes)
 


#finding contours in our captcha

cnts = cv2.findContours(dilation.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)

cnts = sort_contours(cnts, method="left-to-right")[0]   #Sorting contours from left to right 

oo=imgr.copy()
jj=imgr.copy()

#drawing bounding boxes of contours 
for c in cnts:
    (x, y, w, h) = cv2.boundingRect(c)
  
    roi = img1[y:y + h, x:x + w]
    thresh = cv2.threshold(roi, 100, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
    (tH, tW) = thresh.shape
    area=cv2.contourArea(c)
    
    if(area>20):
      print(area," ","###",x," ",y," ",w," ",h)
      cv2.drawContours(oo,c,-1,(255,222,0),1)
      peri=cv2.arcLength(c,True)
      approx=cv2.approxPolyDP(c,0.01*peri,True)
      x, y, w, h=cv2.boundingRect(approx)
      cv2.rectangle(imgr,(x,y),(x+w,y+h),(255,255,255),1)


cv2.imshow("image",imgr)


# new_model = tf.keras.models.load_model(r"C:\Users\Ashish\Desktop\submission\model.h5")  #imported out trained and saved model, enter full path
new_model = tf.keras.models.load_model("model.h5")
classes='ABCEFHJKMNOPSTUWXYZ1234567'                 #define a string depicted the character set taken by us

# Find contours, obtain bounding box, extract and save Region of interest(ROI)


ROI_no = 0
images = []

for c in cnts:
    x,y,w,h = cv2.boundingRect(c)
    area=cv2.contourArea(c)

    if(area>20):
      ROI = jj[y:y+h, x:x+w]

      # cv2.imwrite('/content/segmented_char/ROI_{}.png'.format(ROI_no), ROI)
      images.append(ROI)
      ROI_no += 1

# image_paths = [img for img in glob.glob("/content/segmented_char/*.png")] #get paths of seperated images in captcha

# image_paths.sort()




out=""


for img in images:
   

    
    ht2, wt2,jl = img.shape

    
    if ht2>wt2:     #resizing the image in proportion 28*28, case1  height>width
      
      defh=28
      defx=defh*(wt2/ht2)
      defx = int(defx)

      new = cv2.resize(img, (defx,(int)(defh)),interpolation = cv2.INTER_NEAREST)
      
      h1,w1,_=new.shape

      var = h1-w1

      if var%2==0:
        new2 = cv2.copyMakeBorder(new, 0, 0, int(var/2),int(var/2), cv2.BORDER_REPLICATE)

      else :
        new2 = cv2.copyMakeBorder(new, 0, 0, int(var/2),int(var/2)+1, cv2.BORDER_REPLICATE)


    elif wt2>ht2:       ##resizing the image in proportion 28*28, case2 width>height
      defx=28
      defh=defx*(ht2/wt2)
      defh = int(defh)

      new = cv2.resize(img, (defx,(int)(defh)),interpolation = cv2.INTER_NEAREST)
      
      h1,w1,_=new.shape

      var = w1-h1

      if var%2==0:
        new2 = cv2.copyMakeBorder(new, int(var/2),int(var/2),0,0, cv2.BORDER_REPLICATE)

      else :
        new2 = cv2.copyMakeBorder(new, int(var/2),int(var/2)+1,0,0, cv2.BORDER_REPLICATE)

    else:
     new2 = cv2.resize(img,(28,28), interpolation=cv2.INTER_NEAREST)

  ############################################################################################################
    
    n = cv2.cvtColor(new2,cv2.COLOR_BGR2GRAY)
    d,m=cv2.threshold(n,80,255,cv2.THRESH_BINARY_INV) #converted images to binary image
    # cv2.imshow("m",m)
    imgn = np.expand_dims(m, axis=0)   #converting array into dimension matching with inputs of model
    pred = new_model.predict(imgn)
      
    cv2.waitKey()   #predicting the image
    print(pred)
    cv2.imshow("m",imgn)              
    MaxPosition=np.argmax(pred)        #the maxmimum probability output is the ans predicted by model
    prediction_label=classes[MaxPosition]  # print the image with its 
    print(prediction_label)                # predicted output
    out = out+prediction_label         #update the answer string
    cv2.imshow("image",img)






print("The captcha predicted by model is : ")
print(out)  #Final ans, detected handwritten captcha by model


cv2.imshow("image",imgr)
cv2.waitKey()
